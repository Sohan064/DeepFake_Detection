{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8831eba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Number of images: 2041\n",
      "Shape of X (images): (2041, 224, 224, 3)\n",
      "Number of labels: 2041\n",
      "Labels: ['fake' 'real']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_images_from_directories(real_images_dir, fake_images_dir):\n",
    "    data = []  \n",
    "    labels = []  \n",
    "    try:\n",
    "        for image_file in os.listdir(real_images_dir):  \n",
    "            if image_file.endswith(('.jpg', '.jpeg', '.png', '.bmp')): \n",
    "                image_path = os.path.join(real_images_dir, image_file) \n",
    "                image = cv2.imread(image_path)  \n",
    "               \n",
    "                image = cv2.resize(image, (224, 224))\n",
    "                \n",
    "                image = image.astype(\"float\") / 255.0\n",
    "                data.append(image)  \n",
    "                labels.append(\"real\")  \n",
    "\n",
    "        for image_file in os.listdir(fake_images_dir):  \n",
    "            if image_file.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  \n",
    "                image_path = os.path.join(fake_images_dir, image_file)  \n",
    "                image = cv2.imread(image_path)  \n",
    "                \n",
    "                image = cv2.resize(image, (224, 224))\n",
    "                image = image.astype(\"float\") / 255.0\n",
    "                data.append(image)  \n",
    "                labels.append(\"fake\")  \n",
    "\n",
    "        return np.array(data), np.array(labels)  \n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"One or both directories not found. Please provide the correct paths.\")\n",
    "\n",
    "real_images_dir = r\"C:\\Users\\ranit\\Desktop\\df\\DEEP\\Real\"  \n",
    "fake_images_dir = r\"C:\\Users\\ranit\\Desktop\\df\\DEEP\\Fake\" \n",
    "data, labels = load_images_from_directories(real_images_dir, fake_images_dir)\n",
    "\n",
    "if data is not None and labels is not None:\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(\"Number of images:\", len(data))\n",
    "    print(\"Shape of X (images):\", data.shape)\n",
    "    print(\"Number of labels:\", len(labels))\n",
    "    print(\"Labels:\", np.unique(labels))\n",
    "else:\n",
    "    print(\"Failed to load the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6721f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1632, 224, 224, 3)\n",
      "Shape of X_test: (409, 224, 224, 3)\n",
      "Shape of y_train: (1632,)\n",
      "Shape of y_test: (409,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a03fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 111, 111, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 86528)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               11075712  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11169089 (42.61 MB)\n",
      "Trainable params: 11169089 (42.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "51/51 [==============================] - 70s 1s/step - loss: 0.8205 - accuracy: 0.5325 - val_loss: 0.9846 - val_accuracy: 0.5330\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 65s 1s/step - loss: 0.6924 - accuracy: 0.5619 - val_loss: 0.6611 - val_accuracy: 0.6088\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 68s 1s/step - loss: 0.6652 - accuracy: 0.5999 - val_loss: 0.6667 - val_accuracy: 0.6088\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 67s 1s/step - loss: 0.6342 - accuracy: 0.6520 - val_loss: 0.6651 - val_accuracy: 0.5795\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 71s 1s/step - loss: 0.5792 - accuracy: 0.7034 - val_loss: 0.6934 - val_accuracy: 0.5844\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 75s 1s/step - loss: 0.4799 - accuracy: 0.7635 - val_loss: 0.7981 - val_accuracy: 0.5330\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 73s 1s/step - loss: 0.3595 - accuracy: 0.8352 - val_loss: 1.0462 - val_accuracy: 0.5501\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 71s 1s/step - loss: 0.2155 - accuracy: 0.9161 - val_loss: 1.5017 - val_accuracy: 0.5232\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 71s 1s/step - loss: 0.1248 - accuracy: 0.9547 - val_loss: 1.5734 - val_accuracy: 0.5159\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 71s 1s/step - loss: 0.0701 - accuracy: 0.9779 - val_loss: 2.2564 - val_accuracy: 0.5110\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  \n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "model = create_cnn_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, (y_train == \"fake\").astype(int), \n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_test, (y_test == \"fake\").astype(int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2719ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 4s 302ms/step - loss: 2.2564 - accuracy: 0.5110\n",
      "Test Loss: 2.256429672241211\n",
      "Test Accuracy: 0.5110024213790894\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss, accuracy = model.evaluate(X_test, (y_test == \"fake\").astype(int))\n",
    "\n",
    "\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b248c205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 230ms/step\n",
      "Predicted label: Fake\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "\n",
    "def classify_image(image_path_or_url):\n",
    "    try:\n",
    "        # Check if the provided input is a URL\n",
    "        if image_path_or_url.startswith('http://') or image_path_or_url.startswith('https://'):\n",
    "            # Download the image from the URL\n",
    "            response = requests.get(image_path_or_url)\n",
    "            # Ensure the request was successful\n",
    "            if response.status_code == 200:\n",
    "                # Convert image content to numpy array\n",
    "                image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "                # Read the image using OpenCV\n",
    "                user_image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "                # Check if the image is valid\n",
    "                if user_image is None:\n",
    "                    print(\"Error: Unable to decode image\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(\"Error: Unable to download image from URL\")\n",
    "                return None\n",
    "        else:\n",
    "            # If not a URL, assume it's a local file path\n",
    "            image_path = image_path_or_url\n",
    "            # Read the image using OpenCV\n",
    "            user_image = cv2.imread(image_path)\n",
    "            # Check if the image is valid\n",
    "            if user_image is None:\n",
    "                print(\"Error: Unable to load image at path:\", image_path)\n",
    "                return None\n",
    "        \n",
    "        # Resize image to the required dimensions (224x224)\n",
    "        user_image = cv2.resize(user_image, (224, 224))\n",
    "        # Normalize pixel values to be between 0 and 1\n",
    "        user_image = user_image.astype('float32') / 255.0\n",
    "        user_image = np.expand_dims(user_image, axis=0)\n",
    "        # Pass the preprocessed image through the trained model\n",
    "        predicted_label = model.predict(user_image)\n",
    "        # Convert predicted probability to class label\n",
    "        if predicted_label >= 0.5:\n",
    "            return \"Fake\"\n",
    "        else:\n",
    "            return \"Real\"\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "image_path_or_url = r\"https://miro.medium.com/v2/resize:fit:828/format:webp/0*0zHFF42lGRCCkGSg.jpg\"  # Local file path or online image URL\n",
    "predicted_label = classify_image(image_path_or_url)\n",
    "if predicted_label is not None:\n",
    "    print(\"Predicted label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22eaa612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f5ce33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
